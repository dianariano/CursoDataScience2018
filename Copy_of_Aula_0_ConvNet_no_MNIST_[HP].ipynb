{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Aula 0 - ConvNet no MNIST-[HP].ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "text",
      "language": "python",
      "name": "text"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dianariano/CursoDataScience2018/blob/master/Copy_of_Aula_0_ConvNet_no_MNIST_%5BHP%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "JEl2Fdwxp1Bb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iApJaIJOp1Bh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Atenção: Rode esta linha apenas se estiver usando o Google Colab"
      ]
    },
    {
      "metadata": {
        "id": "jVLQBOCBp1Bk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PF5cv-sAp1Bo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torchvision\n",
        "from matplotlib import pyplot as plt\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Zp67Efqp1Bt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### O código da célula abaixo contém funções para efetuar a carga dos dados, treinamento teste dos modelos"
      ]
    },
    {
      "metadata": {
        "id": "BozZptiup1Bv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_loaders(batch_size):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        dataset=datasets.MNIST(\n",
        "            root='../data', \n",
        "            train=True, \n",
        "            download=True,\n",
        "            transform=transform,\n",
        "        ),\n",
        "        batch_size=batch_size, \n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        dataset=datasets.MNIST(\n",
        "            root='../data', \n",
        "            train=False, \n",
        "            download=True,\n",
        "            transform=transform,\n",
        "        ),\n",
        "        batch_size=batch_size, \n",
        "        shuffle=True\n",
        "    )\n",
        "    return train_loader, test_loader\n",
        "\n",
        "def train_epoch(\n",
        "        model, \n",
        "        device, \n",
        "        train_loader, \n",
        "        optimizer, \n",
        "        criterion, \n",
        "        epoch, \n",
        "        log_interval\n",
        "    ):\n",
        "    model.train()\n",
        "    history = []\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(\n",
        "        model, \n",
        "        device, \n",
        "        criterion, \n",
        "        test_loader\n",
        "    ):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item() # sum up batch loss\n",
        "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        accuracy))\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def train(\n",
        "        model,\n",
        "        train_loader,\n",
        "        test_loader,\n",
        "        device,\n",
        "        lr,\n",
        "        nb_epochs=3,\n",
        "        log_interval=100,\n",
        "    ):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "    for epoch in range(1, nb_epochs + 1):\n",
        "        print('\\n* * * Training * * *')\n",
        "        train_epoch(\n",
        "            model=model, \n",
        "            device=device, \n",
        "            train_loader=train_loader, \n",
        "            optimizer=optimizer, \n",
        "            criterion=criterion, \n",
        "            epoch=epoch, \n",
        "            log_interval=log_interval\n",
        "        )\n",
        "        print('\\n* * * Evaluating * * *')\n",
        "        acc = test(model, device, criterion, test_loader)        \n",
        "    \n",
        "    return acc\n",
        "\n",
        "def check_input(model, device):\n",
        "    dummy_data = torch.zeros(5, 1, 28, 28).to(device)\n",
        "    dummy_pred = model(dummy_data)        \n",
        "    assert dummy_pred.shape == (5, 10), '\\nOutput expected: (batch_size, 10) \\nOutput found   : {}'.format(dummy_pred.shape)\n",
        "    print('Passed')\n",
        "    return dummy_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uT8ajBetp1B1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Hyper-parâmetros que você pode definir"
      ]
    },
    {
      "metadata": {
        "id": "3IyetIBhp1B2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "device_name = 'cpu'\n",
        "nb_epochs = 3\n",
        "log_interval = 500\n",
        "lr = 1e-3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7gRI0Stkp1B7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(device_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "diK1nZ_Ip1B8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Conferência dos dados"
      ]
    },
    {
      "metadata": {
        "id": "tER9hLG9p1B9",
        "colab_type": "code",
        "outputId": "cb09f964-cf96-4a9b-9880-4a6bfb375120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "train_loader, test_loader = get_loaders(batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0LZ8TzPup1B_",
        "colab_type": "code",
        "outputId": "3b6e8e35-44f5-4283-8355-79cf8b841ef1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(\n",
        "    'Train size: ', \n",
        "    train_loader.dataset.train_data.shape, \n",
        "    train_loader.dataset.train_labels.shape\n",
        ")\n",
        "print(\n",
        "    'Test size : ', \n",
        "    test_loader.dataset.test_data.shape, \n",
        "    test_loader.dataset.test_labels.shape\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Train size: ', torch.Size([60000, 28, 28]), torch.Size([60000]))\n",
            "('Test size : ', torch.Size([10000, 28, 28]), torch.Size([10000]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5-4evVwHp1CE",
        "colab_type": "code",
        "outputId": "a6f6e066-4086-4fd0-a35c-c228943f7c3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, 5)\n",
        "for i, ax in enumerate(axs):\n",
        "    ax.imshow(train_loader.dataset.train_data[i], cmap='gray')\n",
        "    ax.set_title(train_loader.dataset.train_labels[i].item())\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABXCAYAAACnZJZlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAADkpJREFUeJzt3XmQndOfx/F3i7EkfiGC2H4I4Rgy\n9ixUighB2SJiLVswKCSMEaOsQ9kFM3YpKvYZUrYQlUHZlzAhqCFyLLFMYo8tiW1Izx83n37uvd1J\nOr/ue57ndn9eVSrdt293f/vRfe73+Z5zvqehsbERMzNLY5m8AzAz60w86JqZJeRB18wsIQ+6ZmYJ\nedA1M0vIg66ZWULL5h0AQAhhA+AD4KOyh/87xnhkPhEVQwhhCHAVsBLwKXB0jHFWvlEVRwhhL2AS\n0DvG+EnO4eQqhPB3wOXAPwN/9e8JhBCOBM4E/gI8D/xjjPG3fKMqyKC70OwY46Z5B1EUIYRuwH3A\nHjHGaSGEU4BbgL3zjawYQghdKQ0y3+UdS0FMBKbmHURRhBD6AtcAWwOzgHuBfwEuyjMucHmhyIYA\nM2OM0xa+Px7YLYTwlxxjKpILgLuBuTnHURQXxRj/Ne8gCmQI8EyM8X9jjI3AvwMjco4JKNag2z2E\n8EgIYUYI4b9CCH+fd0A524SyckuMcR4wB+iTW0QFEUL4B2Ao8G95x1IUMcYpecdQMI1Al7L351GQ\nv52iDLpzgf8A/gnYDHgKmBhCKFL5I7WuwK9Vj/0CdMshlsIIITRQKrOMjjH+X97xWGE9DQwNIfRd\nOI6cDKyQc0xAQQbdGOOcGOOoGOMnMcYFlGoxvShle53VfJr/knSl9IrdmR0PTI8xvpR3IFZcMcbp\nwGhK8yKvAdOBH3INaqFCDLohhB4hhN5VD3cBOnMmM4Oy26EQwspAD0qrPDqzYcCwEMKXIYQvgb8C\nU0MIO+cclxVMjPHOGGPfGOO2wP8s/C93Rbl97weMCyH0jzF+AxwHfAbMzDesXD0LjA8hDFqY1Z0G\nTIoxzs85rlzFGPcsfz+E8AkwuLMvGbNKIYQ+wAPAYEp3jWcDd+QYUpOGorR2DCGcQWmwXQDMBkbF\nGN/LN6p8hRAGA9dSquN+CIyMMX6Za1AF40EXQgi9KK1DBQiUJmD/AHaJMc7OLbCchRAuBEZSmlT7\nzxjjWflGVFKYQdfMrDMoRE3XzKyz8KBrZpaQB10zs4Q86JqZJeRB18wsocWu021oaOgUSxsaGxsb\nWvtcX5OW+bo052vSnK+JM10zs6Q86JqZJeRB18wsIQ+6ZmYJedA1M0vIg66ZWUIedM3MEipKP11r\nhW233RaAUaNGAXDkkaUT6u+66y4Arr/+egCmTZvWwmebWRE40zUzS2ix/XRT7B7p0qV0YOfKK6/c\n4seV1XXt2hWAEAIAJ598MgBXXXUVAIceemjT5/z6a+k8x8svvxyACy+8cLExFH1HzVZbbQXAM888\nA0D37t1bfN6PP/4IQM+ePdv8PTvijrRddtkFgHvvvbfpsZ122gmAGGOrvkbRf1eW5NxzzwWyv4ll\nlinlXYMHD256zvPPP9/s8xan3q9JLXhHmplZQdS8prveeusBsNxyywGwww47ADBo0CAAVlllFQBG\njBjRqq83a9YsAK677joAhg8fDsDcuXObnvP2228DS/+KXTT9+/cH4MEHHwSyuwHdnehn/v3334Es\nwx04cCBQWdvVc/Ky4447AlmMDz/8cPIY+vXrB8DUqVOTf++8jRw5EoAzzzwTgAULFlR83CfIpONM\n18wsoZpkuqpBQlaHXFTNtrX0yqya1Lx584CsPvfFF180Pff7778HWl+nKwrVrbfZZhsA7rnnHgDW\nWmutFp//wQel09ivvPJKAO677z4AXn75ZSC7VgCXXXZZDSJuPdUMN954YyBtpqu6Ze/evQFYf/31\nmz7W0LBUpeu6pZ95hRVWyDmS2hswYAAAhx9+OJDV7TfffPOK540ZMwaAzz//HMjuvvV399prr9Uk\nPme6ZmYJedA1M0uoJuWFzz77rOntOXPmAK0vLyil/+GHHwDYeeedgWwi6O677263OItm3LhxQOXy\nt8VRGWKllVYCsolD3cpvscUW7Rzh304bOaZMmZL8e6s8c9xxxwHZ7SPAjBkzkseT0q677grA6NGj\nKx7Xz7333nsD8NVXX6UNrAYOPvhgAK699loAVlttNSArIT333HMArL766gCMHTu24vP1PH38kEMO\nqUmcznTNzBKqSab73XffNb19xhlnANkr6ptvvglkS77krbfeAmDo0KEAzJ8/H8iK36eeemotQi0E\nbe/da6+9gOaTO8pgH3vsMSDbEKIJAF1TTSAOGTKkxa+TJ01m5eG2226reF8TkB2ZJoVuv/12oPmd\nprK8Tz/9NG1g7WjZZUvD13bbbQfArbfeCmQT0i+88AIAF110EQAvvfQSAMsvvzwAEyZMAGC33Xar\n+Lqvv/56LcN2pmtmllLNN0c88sgjQLZ0TAv6t9xySwCOPfZYIMvelOHKu+++C8Dxxx9f61CT09K6\np556Csi292qh+uTJk4GsxqulL1oKpgzum2++AbJNIVpep8wZsvpv6mY4qiv36tUr6fctV53l6Xp3\nZEcddRQAa6+9dsXjqmuqSVI905Kw6jsZ/f9Vjfenn36q+Lger85wtfHqzjvvbP9gyzjTNTNLKFlr\nx+pXGzVnEc0s33///UDzbYodySabbAJk9W5lYt9++y2QbfTQK642gjz++OMV/y7Jiiuu2PT26aef\nDsBhhx3WptiX1p577tksllSUXWtThMyePTt5LKloxv6YY44Bsr8jrQa6+OKL8wmsHalGe/bZZwPZ\nneFNN90EZHeC1WOOnHPOOS0+fsoppwDZnWOtONM1M0sotybmF1xwAZDN3KteqXWFTz75ZC5x1Ypm\nTCGrXysLVJ1ba1k1e9qe2aEaD6WmVpyiGn0Kus7KeN9//32gsjlSR7HBBhsAWXOkampw/+yzz6YK\nqV2df/75TW8rw9Xa/SeeeALImvn88ssvFZ+rrc+q4epvQat7lP1PnDixJrFXc6ZrZpZQbpmuVimo\nlqtZda210yuysr4bb7wRqN8WdFtvvXXT28pwZdiwYUD9t6JsjVq0VdSqjz322APIZrWrZ6dVC1R9\nsyPRz169C/Hpp58Gsl1a9UatX0866aSmxzQGKMPdb7/9WvzcPn36AFlTLN1VywMPPABkDaNScaZr\nZpZQ7gdTfvTRR0DWZFk7aI444oiKf7t16wZk6wvLWznWg2uuuabpbdWSlNm2d4ar3V9FXAGy6qqr\nLvE5WsOt66Q6/7rrrgtkDfG1EkM/r2p56t/x22+/AdnOpTfeeKPtP0DBKMvT0VSi3Vdar1u9Wqhe\n6P+1VmWU02qDNdZYA4Cjjz4agH333ReAvn37AllvEmXI+lc9OKr3BtSaM10zs4Ryz3RFTa21L16Z\noQ4TvPTSS4GsGfMll1wCFH/NpXpOlDd21yvto48+WpPvqQy3vP6t3hapKftULLfccguQzUC3RHVJ\nZbp//PEHAD///DMA06dPB2D8+PFAVvfXHYM6ZmmHkVaBdKSOYktarTBz5kyg/ruHaYVC+dpZdQH7\n+OOPgUXP86g3idbrqtuc1sOrl0lqznTNzBIqTKYr77zzDgAHHXQQAPvssw+Q1XpPOOEEIDv2RV3J\nikpZlmpTAF9//TWQ7b5rK60B1tpnUb8LgLPOOqtdvtfS0qyzulnpYNLFUT9m9e147733AHj11Vdb\n9T3Vp0MZkbK+jmRRB0xKdY23XmmlSfkKhUmTJgHZ/IDmhbTO9o477gCyboc6xkqZrt7PizNdM7OE\nCpfpil7hdFKEOglpJlpHeuuUBHVPqgeaVW/rCgxluNprrl4OqmVeffXVTc9V/4a8XHHFFcm+l+YB\nZFF1z3qkuYHqNciibK/eDmVdkvJDInUHsyQaI7TbVXcFed/5ONM1M0uocJmuZq4POOAAAPr16wdk\nGa5oBlvd4etJW1ctKNtRZqv+oMpyRowY0aav39GkPO691tSTpEePHhWPq96t9e6WzadUr+ZxTdfM\nrBPJPdNVF6pRo0YBsP/++wOw5pprtvj8P//8E8jqoUXcdVVOa03LzyvTTOzSnvt22mmnAXDeeecB\nWR9e7S1XlzLruHr27Ak0/71XL9m8a/dFot4MReNM18wsoeSZrjJYnfulDFc7bBZFu460E61Wu7na\nW/V+b8iugU5E1s6qOXPmADBw4EAg6zuhXgTqPaB1rHolV5ZjlXR3oZM6WrvOt4i0Tn1Rpyq/8sor\nKcOpC7vvvnveIbTIma6ZWUI1z3TVtX+zzTYD4IYbbgBg0003XeznaV3e2LFjgWxmvug13Nbo0qUL\nkO3W0moD7RHXbrtqymbUa7i8m741p7uLRWWH9UArVdRpTb//6kmgPtP13mOhFjbccMO8Q2hR/f42\nmpnVIQ+6ZmYJtWt5QQ0oxo0b1/SYbo+WlOrr1llbVzVJVH3IXL2ZMmUKUHlMjTZ8iCbWVIoRTaxp\nMffSLjGzku233x7IGqHUEx1XU72EUi1Nx4wZkzymevHiiy8CxWvq70zXzCyhNmW6AwYMALLtqP37\n9wdgnXXWWeLnqiG1lk2pSXnqozNqTc1ntOkDsvaUalRTTYcI3nzzzQB8+OGHtQyxwyrfkGKdj9rE\n6mAE3W1vtNFGQGVj9JSc6ZqZJdSmTHf48OEV/7ZEjWnUeFhHr6h22xGPw25JeRtHNRuvbjpu7WPy\n5MkAHHjggTlH0nY6YkhzHoMGDcoznLqku2i1h9UGq9GjRwPZGJWKM10zs4QaFnWoG0BDQ8OiP9iB\nNDY2trr452vSMl+X5nxNmsvjmnTv3h2ACRMmANlGk4ceegjIjm5vz/mkxV0TZ7pmZgk506X4r9R5\ncKbbMv+uNFcv10QZr2q6J554IpAdnNCetV1numZmBeFMl/p5pU7JmW7L/LvSnK9Jc850zcwKYrGZ\nrpmZtS9numZmCXnQNTNLyIOumVlCHnTNzBLyoGtmlpAHXTOzhP4fwBspBDNsDd4AAAAASUVORK5C\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "kV4tbXnCp1CF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "instance = next(iter(train_loader))\n",
        "print('Instance Example: ', instance[0].shape, instance[1].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CG40TdZSp1CH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Seu trabalho começa aqui:"
      ]
    },
    {
      "metadata": {
        "id": "GVZZEyHxp1CI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Implemente aqui sua primeira rede convolucional  \n",
        "\n",
        "Sua ConvNet deve ser capaz de classificar as imagens do MNIST. Lembre-se que as imagens do MNIST tem apenas 1 canal, isto é, elas são em escala de cinza (e não RBG!)."
      ]
    },
    {
      "metadata": {
        "id": "fuXUek-Cp1CI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv_1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.conv_2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.fc = nn.Linear(in_features=3136, out_features=10)\n",
        "        \n",
        "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.shape[0], 64*7*7) # Ou x = x.view(x.shape[0], -1)\n",
        "        out = self.fc(x)\n",
        "        return out "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GxQZF-hzp1CJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.1 Verifique se a saída do seu modelo está correta"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "neT7BXISp1CK",
        "colab_type": "code",
        "outputId": "13c2b71f-4ed5-43f5-9345-c7386b039766",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model = ConvNet().to(device)\n",
        "dummy_pred = check_input(model, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pI2dOw4zp1CP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.2 Treine seu modelo por uma ou mais épocas. \n",
        "\n",
        "Você deve conseguir ~99% de acurácia na terceira época. "
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "mp-9CVndp1CP",
        "colab_type": "code",
        "outputId": "15ffad75-ea02-41c3-ce3f-e045bf1eeed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "cell_type": "code",
      "source": [
        "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
        "print('Final acc: {:.2f}%'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.344822\n",
            "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.057254\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.035814\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.302291\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.027999\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.003220\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.008364\n",
            "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.021339\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0032, Accuracy: 9828/10000 (98.28%)\n",
            "\n",
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.011703\n",
            "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.003758\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.002411\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.002191\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.005496\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.005708\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.073575\n",
            "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.092041\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0021, Accuracy: 9890/10000 (98.90%)\n",
            "\n",
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.000291\n",
            "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.001891\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.002902\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.000079\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.005027\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.002196\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.041109\n",
            "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.039501\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0023, Accuracy: 9884/10000 (98.84%)\n",
            "\n",
            "Final acc: 98.84%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U-F9GKGxp1CT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Atualize sua rede convolucional para usar o container nn.Sequential()\n",
        "\n",
        "A arquitetura da rede pode ser exatamente igual à rede anterior, porém, agora use o nn.Sequential para criar as camadas."
      ]
    },
    {
      "metadata": {
        "id": "PmNVOCNQvjtK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Flatten(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(Flatten, self).__init__()\n",
        "      pass\n",
        "    \n",
        "  def forward(self, x):\n",
        "      x = x.view(x.shape[0], -1)\n",
        "      return x\n",
        "  \n",
        " \n",
        " \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3duS_YY-p1CT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ConvNetSeq(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNetSeq, self).__init__()\n",
        "        conv_1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "        conv_2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        flatten = Flatten()\n",
        "        fc = nn.Linear(in_features=3136, out_features=10)\n",
        "        \n",
        "        pool = nn.MaxPool2d(kernel_size=2)\n",
        "        relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.conv = nn.Sequential(*[\n",
        "            conv_1, relu, pool, conv_2, relu, pool, flatten, fc\n",
        "        ])    \n",
        "        \n",
        "        \n",
        "    def forward(self, x): \n",
        "        return self.conv(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "YoYnZOvYp1CV",
        "colab_type": "code",
        "outputId": "effdfe98-871b-4572-ee92-8120ee118330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "model = ConvNetSeq().to(device)\n",
        "print(model)\n",
        "dummy_pred = check_input(model, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ConvNetSeq(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Flatten()\n",
            "    (7): Linear(in_features=3136, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7Hc-DR2ep1CX",
        "colab_type": "code",
        "outputId": "7d1f99c1-d1e4-4950-da38-b0a2acd076dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "cell_type": "code",
      "source": [
        "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
        "print('Final acc: {:.2f}%'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.272963\n",
            "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.586237\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.018319\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.290589\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.011676\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.135997\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.002326\n",
            "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.307112\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0028, Accuracy: 9867/10000 (98.67%)\n",
            "\n",
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.000879\n",
            "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.006896\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.014080\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.001082\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.034609\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.201327\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.139107\n",
            "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.033626\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0027, Accuracy: 9868/10000 (98.68%)\n",
            "\n",
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.019531\n",
            "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.007346\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.000331\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.002556\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.054430\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.000211\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.085532\n",
            "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.002778\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0020, Accuracy: 9887/10000 (98.87%)\n",
            "\n",
            "Final acc: 98.87%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CS7-wGlJp1CZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Crie uma nova rede substituindo as camadas de convolução da sua rede anterior por blocos Inception.  \n",
        "\n",
        "Detalhes:\n",
        "\n",
        "1. Crie um novo módulo (classe que herda do nn.Module) chamado de InceptionModule. \n",
        "2. Nesse módulo você deverá criar camadas convolucionais com filtros 1x1, 3x3 e 5x5 paralelamente. No final, concatene o resultado, e aplique mais uma convolução 1x1 para reduzir a dimensionalidade ao tamanho original. \n",
        "2. Atualize sua rede convolucional substituindo as camadas de convolução pelo seu bloco Inception. \n",
        "3. Treine o modelo e reporte a acurácia. "
      ]
    },
    {
      "metadata": {
        "id": "ebDaoxaep1CZ",
        "colab_type": "code",
        "outputId": "4d84351c-a703-4a4a-f0e9-140f0c71bd04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "class InceptionModule(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(InceptionModule, self).__init__()\n",
        "        \n",
        "        self.conv_1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1)  \n",
        "        self.conv_2 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1) \n",
        "        self.conv_3 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=5, padding=2)  \n",
        "        self.conv_r = nn.Conv2d(in_channels=out_channels*3, out_channels=out_channels, kernel_size=1)         \n",
        "         \n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x): \n",
        "        \n",
        "        a = self.conv_1(x)\n",
        "        a = self.relu(a)\n",
        "        b = self.conv_2(x)\n",
        "        b = self.relu(b)\n",
        "        c = self.conv_3(x)\n",
        "        c = self.relu(c)\n",
        "        x = torch.cat([a, b, c], dim=1)\n",
        "        \n",
        "        out = self.relu(self.conv_r(x))\n",
        "        return out\n",
        "        \n",
        "model = InceptionModule(1, 32)\n",
        "print(model)\n",
        "pred = model(torch.zeros(1,1,28,28))\n",
        "print(pred.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "InceptionModule(\n",
            "  (conv_1): Conv2d(1, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (conv_2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv_3): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (conv_r): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (relu): ReLU(inplace)\n",
            ")\n",
            "torch.Size([1, 32, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aqpWrjmbp1Cb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class InceptionNet(nn.Module):\n",
        "    def __init__(self,):\n",
        "        super(InceptionNet, self).__init__() \n",
        "        conv_1 = InceptionModule(in_channels=1, out_channels=8)\n",
        "        conv_2 = InceptionModule(in_channels=8, out_channels=16)\n",
        "        flatten = Flatten()\n",
        "        fc = nn.Linear(in_features=784, out_features=10)\n",
        "        \n",
        "        pool = nn.MaxPool2d(kernel_size=2)\n",
        "        relu = nn.ReLU()\n",
        "        \n",
        "        self.conv = nn.Sequential(*[\n",
        "            conv_1, relu, pool, conv_2, relu, pool, flatten, fc\n",
        "        ]) \n",
        "       \n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TNp9YHdFp1Ce",
        "colab_type": "code",
        "outputId": "99504195-d3f7-41c1-862b-4aec883c8545",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "cell_type": "code",
      "source": [
        "model = InceptionNet().to(device)\n",
        "print(model)\n",
        "dummy_pred = check_input(model, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "InceptionNet(\n",
            "  (conv): Sequential(\n",
            "    (0): InceptionModule(\n",
            "      (conv_1): Conv2d(1, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (conv_2): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_3): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "      (conv_r): Conv2d(24, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): InceptionModule(\n",
            "      (conv_1): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (conv_2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_3): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "      (conv_r): Conv2d(48, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (relu): ReLU(inplace)\n",
            "    )\n",
            "    (4): ReLU()\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Flatten()\n",
            "    (7): Linear(in_features=784, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ErPIfOZVp1Ch",
        "colab_type": "code",
        "outputId": "eaf446b1-9569-484d-b69a-2c1a7fbc1365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "cell_type": "code",
      "source": [
        "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
        "print('Final acc: {:.2f}%'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.290423\n",
            "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.453755\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.118246\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.134753\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.033968\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.343004\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.116794\n",
            "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.052457\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0036, Accuracy: 9807/10000 (98.07%)\n",
            "\n",
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.083793\n",
            "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.063509\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.013913\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.005346\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.000926\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.003476\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.007351\n",
            "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.149278\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0029, Accuracy: 9846/10000 (98.46%)\n",
            "\n",
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.157949\n",
            "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.043606\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.149625\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.005836\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.039592\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.008292\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.016649\n",
            "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.008291\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0026, Accuracy: 9863/10000 (98.63%)\n",
            "\n",
            "Final acc: 98.63%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hBZ3ltUtJfbD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}