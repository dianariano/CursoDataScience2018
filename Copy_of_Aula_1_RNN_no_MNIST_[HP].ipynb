{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Aula 1 - RNN no MNIST-[HP].ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "vse27",
      "language": "python",
      "name": "vse27"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dianariano/CursoDataScience2018/blob/master/Copy_of_Aula_1_RNN_no_MNIST_%5BHP%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "gdUE_Dj05e7U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "av7H-2BZ5e7Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Atenção: Rode esta linha apenas se estiver usando o Google Colab"
      ]
    },
    {
      "metadata": {
        "id": "qjK15BKK5e7Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VOB8uptC5e7a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torchvision\n",
        "from matplotlib import pyplot as plt\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t7ggooSE5e7c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### O código da célula abaixo contém funções para efetuar a carga dos dados, treinamento teste dos modelos"
      ]
    },
    {
      "metadata": {
        "id": "bnhOvhrL5e7d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_loaders(batch_size):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        dataset=datasets.MNIST(\n",
        "            root='../data', \n",
        "            train=True, \n",
        "            download=True,\n",
        "            transform=transform,\n",
        "        ),\n",
        "        batch_size=batch_size, \n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        dataset=datasets.MNIST(\n",
        "            root='../data', \n",
        "            train=False, \n",
        "            download=True,\n",
        "            transform=transform,\n",
        "        ),\n",
        "        batch_size=batch_size, \n",
        "        shuffle=True\n",
        "    )\n",
        "    return train_loader, test_loader\n",
        "\n",
        "def train_epoch(\n",
        "        model, \n",
        "        device, \n",
        "        train_loader, \n",
        "        optimizer, \n",
        "        criterion, \n",
        "        epoch, \n",
        "        log_interval\n",
        "    ):\n",
        "    model.train()\n",
        "    history = []\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(\n",
        "        model, \n",
        "        device, \n",
        "        criterion, \n",
        "        test_loader\n",
        "    ):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item() # sum up batch loss\n",
        "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        accuracy))\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def train(\n",
        "        model,\n",
        "        train_loader,\n",
        "        test_loader,\n",
        "        device,\n",
        "        lr,\n",
        "        nb_epochs=3,\n",
        "        log_interval=100,\n",
        "    ):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "    for epoch in range(1, nb_epochs + 1):\n",
        "        print('\\n* * * Training * * *')\n",
        "        train_epoch(\n",
        "            model=model, \n",
        "            device=device, \n",
        "            train_loader=train_loader, \n",
        "            optimizer=optimizer, \n",
        "            criterion=criterion, \n",
        "            epoch=epoch, \n",
        "            log_interval=log_interval\n",
        "        )\n",
        "        print('\\n* * * Evaluating * * *')\n",
        "        acc = test(model, device, criterion, test_loader)        \n",
        "    \n",
        "    return acc\n",
        "\n",
        "def check_input(model, device):\n",
        "    dummy_data = torch.zeros(5, 1, 28, 28).to(device)\n",
        "    dummy_pred = model(dummy_data)        \n",
        "    assert dummy_pred.shape == (5, 10), '\\nOutput expected: (batch_size, 10) \\nOutput found   : {}'.format(dummy_pred.shape)\n",
        "    print('Passed')\n",
        "    return dummy_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cPwkg4hk5e7e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Hyper-parâmetros que você pode definir"
      ]
    },
    {
      "metadata": {
        "id": "S7xoDOr25e7f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "device_name = 'cpu'\n",
        "nb_epochs = 3\n",
        "log_interval = 500\n",
        "lr = 1e-3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6aT8PAkR5e7i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(device_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y-swpi5E5e7j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Conferência dos dados"
      ]
    },
    {
      "metadata": {
        "id": "uvXPe-NG5e7k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loader, test_loader = get_loaders(batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mPbRJCAR5e7n",
        "colab_type": "code",
        "outputId": "79e85049-4df2-49d5-d330-ad25f7df3c0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(\n",
        "    'Train size: ', \n",
        "    train_loader.dataset.train_data.shape, \n",
        "    train_loader.dataset.train_labels.shape\n",
        ")\n",
        "print(\n",
        "    'Test size : ', \n",
        "    test_loader.dataset.test_data.shape, \n",
        "    test_loader.dataset.test_labels.shape\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Train size: ', torch.Size([60000, 28, 28]), torch.Size([60000]))\n",
            "('Test size : ', torch.Size([10000, 28, 28]), torch.Size([10000]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ev77KYFp5e7r",
        "colab_type": "code",
        "outputId": "16abae1a-26f3-4309-8d53-6e99e23e0700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "instance = next(iter(train_loader))\n",
        "print('Instance Example: ', instance[0].shape, instance[1].shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Instance Example: ', torch.Size([16, 1, 28, 28]), torch.Size([16]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DXauBmUkESxE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xPYD2YcW5e7t",
        "colab_type": "code",
        "outputId": "4765b481-3c38-42ea-96e7-688696ba5071",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, 5)\n",
        "for i, ax in enumerate(axs):\n",
        "    ax.imshow(train_loader.dataset.train_data[i], cmap='gray')\n",
        "    ax.set_title(train_loader.dataset.train_labels[i].item())\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABXCAYAAACnZJZlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "BAtsd77uER1F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LSTMtest(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTMtest, self).__init__()  \n",
        "        self.conv_1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv_2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)        \n",
        "        self.fc = nn.Linear(in_features = 3136, out_features = 10)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "    def forward(self, x):\n",
        "         x = self.conv_1(x)\n",
        "         x = self.relu(x)\n",
        "         x = self.pool(x)\n",
        "         x = self.relu(self.conv_2(x))\n",
        "         x = self.pool(x)\n",
        "         x = x.view(x.shape[0], 64*7*7)\n",
        "         out = self.fc(x)\n",
        "         return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5RVnPm_8HyLh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "2c2373ed-0716-4c69-99df-b2cd17b9ff09"
      },
      "cell_type": "code",
      "source": [
        "model = LSTMtest()\n",
        "print(model)\n",
        "dummy_data = torch.zeros(5, 1, 28, 28).to(device)\n",
        "dummy_pred = model(dummy_data)\n",
        "print(dummy_pred.shape)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTMtest(\n",
            "  (conv_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc): Linear(in_features=3136, out_features=10, bias=True)\n",
            "  (relu): ReLU(inplace)\n",
            ")\n",
            "torch.Size([5, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u-pjWY9R5e7v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Seu trabalho começa aqui:"
      ]
    },
    {
      "metadata": {
        "id": "n5R7P6Hy5e7w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Implemente aqui sua primeira arquitetura com `nn.LSTM()` \n",
        "\n",
        "Sua LSTM deve ser capaz de classificar as imagens do MNIST processando de forma recorrente as linhas ou colunas. Lembre-se que as imagens do MNIST tem apenas 1 canal, isto é, elas são em escala de cinza (e não RBG!). \n",
        "* Spoiler: LSTM com 32 neurônios, atinge ~96% de acurácia em 3 épocas. "
      ]
    },
    {
      "metadata": {
        "id": "596Qb-Dx5e7x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DigitsLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(DigitsLSTM, self).__init__()  \n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Set initial hidden and cell states \n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        # Forward propagate LSTM\n",
        "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
        "        \n",
        "        # Decode the hidden state of the last time step\n",
        "        out = self.fc(out[:, -1, :])\n",
        "    \n",
        "        return out\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r4aGPY125e7y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.1 Verifique se a saída do seu modelo está correta"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "fXV11bWF5e7z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "5ad3e505-4768-4421-eaed-221406182214"
      },
      "cell_type": "code",
      "source": [
        "model = DigitsLSTM().to(device)\n",
        "dummy_pred = check_input(model, device)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-4106dc97429d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDigitsLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdummy_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'input_size' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "dvDThlYc5e71",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.2 Treine seu modelo por uma 1 época\n",
        "Valores de acc esperados por época: \n",
        "1. 93.5%\n",
        "2. 94.5%\n",
        "3. 96.8%"
      ]
    },
    {
      "metadata": {
        "id": "QREGhErB5e72",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "040280ee-696e-4ebf-8e48-3381ed6c6fd6"
      },
      "cell_type": "code",
      "source": [
        "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
        "print('Final acc: {:.2f}%'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.289752\n",
            "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.008689\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.073460\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.011018\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.002669\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.002149\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.084579\n",
            "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.044944\n",
            "\n",
            "* * * Evaluating * * *\n",
            "Test set: Average loss: 0.0032, Accuracy: 9848/10000 (98.48%)\n",
            "\n",
            "\n",
            "* * * Training * * *\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.005066\n",
            "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.185241\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.004104\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.012126\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.001919\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.007694\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.001188\n",
            "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.000781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LrorjGj25e73",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Implemente aqui sua arquitetura com `nn.LSTMCell()` \n",
        "\n",
        "Semelhante à arquitetura anterior, sua LSTM deve processar imagens do MNIST iterando sobre as linhas ou as colunas das imagens. A diferença é que agora você deve implementar utilizando uma nn.LSTMCell(). Para isso, você deverá utilizar um laço de repetição `for`."
      ]
    },
    {
      "metadata": {
        "id": "ik5JOY3L5e74",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DigitsCellLSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DigitsCellLSTM, self).__init__()\n",
        "        \n",
        "    def forward(self, x):        \n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "NmStYwGq5e76",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = DigitsCellLSTM(device=device).to(device)\n",
        "dummy_pred = check_input(model, device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xz8gBdgo5e79",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
        "print('Final acc: {:.2f}%'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_7z_C6UJ5e8A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Fique à vontade para testar outras variações das suas arquiteturas para conseguir resultados melhores\n",
        "\n",
        "Ideias: \n",
        "* Aumente o número de camadas na LSTM\n",
        "* Teste GRU\n",
        "* Teste arquiteturas bidirecionais"
      ]
    },
    {
      "metadata": {
        "id": "KDvx57kb5e8B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class YourLSTM(nn.Module):\n",
        "    def __init__():\n",
        "        super(YourLSTM, self).__init__()            \n",
        "\n",
        "    def forward(self, x):        \n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}